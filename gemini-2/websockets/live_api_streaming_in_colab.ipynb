{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vorpalstrikes/vorps-engineer/blob/main/gemini-2/websockets/live_api_streaming_in_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWESX0tpdrE-"
      },
      "source": [
        "##### Copyright 2024 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YQvTrJpxzRlJ"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hp_P0cDzTWp"
      },
      "source": [
        "# Gemini 2.0 - Multimodal live API: Streaming in Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLW8VU78zZOc"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/gemini-2/websockets/live_api_streaming_in_colab.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7f4kFby0E6j"
      },
      "source": [
        "This notebook uses the Multimodel Live API to stream bidirectional audio in Colab. This notebook is much more a **demo** than a tutorial. This code demonstrates that it is possible to stream audio with interruptions in Colab. It takes a few hacks to make it work.\n",
        "\n",
        "* For an overview of the Live API, see the [Live API docs](https://ai.google.dev/api/multimodal-live).\n",
        "* If you want a good live API experience, try the [Live API in Google AI Studio](https://aistudio.google.com/app/live).\n",
        "* If you want to learn how the Live API works, please refer to the [Live API starter tutorial](../live_api_starter.ipynb).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSUz31fds3Z9"
      },
      "source": [
        "### Set up\n",
        "\n",
        "To run the following cell, your API key must be stored in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see [Authentication](../../quickstarts/Authentication.ipynb) for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCwTqSAKsYPI"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6hvdOmqs1lT"
      },
      "source": [
        "Now to run it just run all the cells.\n",
        "\n",
        "**Important**: On first try it will typically throw an error and ask for permission to record audio, if that happens allow audio, and **run it again**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "i7Hc33s8lPjg"
      },
      "outputs": [],
      "source": [
        "# @title Install stuff, monkey patch old Python {display-mode: 'form'}\n",
        "!pip install -q websockets taskgroup\n",
        "\n",
        "# we run on ancient Python (2021), need backport of taskgroup\n",
        "# monkey patch:\n",
        "import asyncio, taskgroup, exceptiongroup\n",
        "asyncio.TaskGroup = taskgroup.TaskGroup\n",
        "asyncio.ExceptionGroup = exceptiongroup.ExceptionGroup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LDTWCuZyl-zd"
      },
      "outputs": [],
      "source": [
        "# @title Inline copy of colab_stream {display-mode: 'form'}\n",
        "import asyncio, contextlib, json\n",
        "from google.colab import output\n",
        "from IPython import display\n",
        "\n",
        "# alt:\n",
        "# message.WaitForRawInput()\n",
        "# colab.frontend.sendMessage({'action': 'keyboard_input', 'payload': state.send});\n",
        "\n",
        "_start_session_js = \"\"\"\n",
        "let start_session = (userFn) => {\n",
        "  let debug = console.log;\n",
        "  debug = ()=>{};\n",
        "\n",
        "  let ctrl = new AbortController();\n",
        "  let state = {\n",
        "    recv: [],\n",
        "    onRecv: () => {},\n",
        "    send: [],\n",
        "    onDone: new Promise((acc) => ctrl.signal.addEventListener('abort', () => acc())),\n",
        "    write: (data) => {\n",
        "      state.send.push(data);\n",
        "    }\n",
        "  };\n",
        "  window._js_session_on_poll = (data) => {\n",
        "    debug(\"on_poll\", data);\n",
        "    for (let msg of data) {\n",
        "      if ('data' in msg) {\n",
        "        state.recv.push(msg.data);\n",
        "      }\n",
        "      if ('error' in msg) {\n",
        "        ctrl.abort(new Error('Remote: ' + msg.error));\n",
        "      }\n",
        "      if ('finish' in msg) {\n",
        "        // TODO\n",
        "        ctrl.abort(new Error('Remote: finished'));\n",
        "      }\n",
        "    }\n",
        "    state.onRecv();\n",
        "    let result = state.send;\n",
        "    state.send = [];\n",
        "    debug(\"on_poll: result\", result);\n",
        "    return result;\n",
        "  };\n",
        "  let connection = {\n",
        "    signal: ctrl.signal,\n",
        "    read: async () => {\n",
        "      while(!ctrl.signal.aborted) {\n",
        "        if (state.recv.length != 0) {\n",
        "          return state.recv.shift();\n",
        "        }\n",
        "        await Promise.race([\n",
        "          new Promise((acc) => state.onRecv = acc),\n",
        "          state.onDone,\n",
        "        ]);\n",
        "      }\n",
        "    },\n",
        "    write: (data) => {\n",
        "      state.write({'data': data});\n",
        "    }\n",
        "  };\n",
        "  debug(\"starting userFn\");\n",
        "  userFn(connection).then(() => {\n",
        "    debug(\"userFn finished\");\n",
        "    ctrl.abort(new Error(\"end of input\"));\n",
        "    state.write({'finished': true});\n",
        "  },\n",
        "  (e) => {\n",
        "    debug(\"userFn error\", e);\n",
        "    console.error(\"Stream function failed\", e);\n",
        "    ctrl.abort(e);\n",
        "    state.write({'error': '' + e});\n",
        "  });\n",
        "};\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class Connection:\n",
        "\n",
        "  def __init__(self):\n",
        "    self._recv = []\n",
        "    self._on_recv_ready = asyncio.Event()\n",
        "    self._send = []\n",
        "    self._on_done = asyncio.Future()\n",
        "\n",
        "  async def write(self, data):\n",
        "    self._send.append({'data': data})\n",
        "\n",
        "  async def read(self):\n",
        "    while not self._on_done.done() and not self._recv:\n",
        "      self._on_recv_ready.clear()\n",
        "      await self._on_recv_ready.wait()\n",
        "    # print(\"read, done waiting: \", self._recv, self._on_done)\n",
        "    if self._on_done.done() and self._on_done.exception() is not None:\n",
        "      raise self._on_done.exception()\n",
        "    elif self._recv:\n",
        "      return self._recv.pop(0)\n",
        "    else:\n",
        "      return EOFError('End of stream')\n",
        "\n",
        "  def _poll(self):\n",
        "    # Polling is needed as ipykernel has blocking mainloop\n",
        "    # (Comms do not work)\n",
        "    # print(\"calling poll\")\n",
        "    res = output.eval_js(f'window._js_session_on_poll({json.dumps(self._send)})')\n",
        "    # print(\"poll: \", res)\n",
        "    self._send = []\n",
        "    for r in res:\n",
        "      if 'data' in r:\n",
        "        self._recv.append(r['data'])\n",
        "        self._on_recv_ready.set()\n",
        "      elif 'error' in r:\n",
        "        self._on_done.set_exception(Exception('Remote error: ' + r['error']))\n",
        "        self._on_recv_ready.set()\n",
        "      elif 'finished' in r:\n",
        "        self._on_done.set_result(None)\n",
        "        self._on_recv_ready.set()\n",
        "\n",
        "  async def _pump(self, pump_interval):\n",
        "    while not self._on_done.done():\n",
        "      self._poll()\n",
        "      await asyncio.sleep(pump_interval)\n",
        "\n",
        "\n",
        "@contextlib.asynccontextmanager\n",
        "async def RunningLiveJs(userCode, pump_interval=0.1):\n",
        "  \"\"\"Runs given javascript async code connecting it to colab.\n",
        "\n",
        "  Use .write(msg) and .read() methods on this context manager\n",
        "  to exchange messages with JavaScript code.\n",
        "\n",
        "  From JavaScript use 'connection.write(data)'\n",
        "  and 'await connection.read()' to exchange messages with colab.\n",
        "  \"\"\"\n",
        "  c = Connection()\n",
        "  output.eval_js(\n",
        "      f\"\"\"\n",
        "    let userFn = async (connection) => {{\n",
        "      {userCode}\n",
        "    }};\n",
        "    {_start_session_js};\n",
        "    start_session(userFn);\n",
        "    1;\n",
        "  \"\"\",\n",
        "      ignore_result=True\n",
        "  )\n",
        "  t = asyncio.create_task(c._pump(pump_interval))\n",
        "\n",
        "  def log_error(f):\n",
        "    if f.exception() is not None:\n",
        "      print('error: ', f.exception())\n",
        "\n",
        "  t.add_done_callback(log_error)\n",
        "  try:\n",
        "    yield c\n",
        "  finally:\n",
        "    t.cancel()\n",
        "    output.eval_js(\n",
        "        \"\"\"window._js_session_on_poll([{finish: true}]);\"\"\", ignore_result=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lR8Pbzu6pcda"
      },
      "outputs": [],
      "source": [
        "# @title Inline copy of colab_audio {display-mode: 'form'}\n",
        "\n",
        "\"\"\"Realtime Audio I/O support.\n",
        "\n",
        "Example use:\n",
        "\n",
        "  async with colab_audio.RunningLiveAudio() as audio:\n",
        "    bytes_per_second = audio.config.sample_rate * audio.config.frame_size\n",
        "    print ('recording (3sec)')\n",
        "    buf = b''\n",
        "    while len(buf) < 3*bytes_per_second:\n",
        "      buf += await audio.read()\n",
        "    print ('playing')\n",
        "    await audio.enqueue(buf)\n",
        "    await asyncio.sleep(3)\n",
        "    print ('done')\n",
        "    display.display(colab_audio.Audio(audio.config, buf))\n",
        "\"\"\"\n",
        "\n",
        "import asyncio\n",
        "import base64\n",
        "from collections.abc import AsyncIterator\n",
        "import contextlib\n",
        "import dataclasses\n",
        "import io\n",
        "import json\n",
        "import time\n",
        "import wave\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "@dataclasses.dataclass(frozen=True)\n",
        "class AudioConfig:\n",
        "  \"\"\"Configuration of audio stream.\"\"\"\n",
        "\n",
        "  sample_rate: int\n",
        "  format: str = 'S16_LE'  # only supported value\n",
        "  channels: int = 1  # only supported value\n",
        "\n",
        "  @property\n",
        "  def sample_size(self) -> int:\n",
        "    assert self.format == 'S16_LE'\n",
        "    return 2\n",
        "\n",
        "  @property\n",
        "  def frame_size(self) -> int:\n",
        "    return self.channels * self.sample_size\n",
        "\n",
        "  @property\n",
        "  def numpy_dtype(self) -> np.dtype:\n",
        "    assert self.format == 'S16_LE'\n",
        "    return np.dtype(np.int16).newbyteorder('<')\n",
        "\n",
        "\n",
        "@dataclasses.dataclass(frozen=True)\n",
        "class Audio:\n",
        "  \"\"\"Unit of audio data with configuration.\"\"\"\n",
        "\n",
        "  config: AudioConfig\n",
        "  data: bytes\n",
        "\n",
        "  @staticmethod\n",
        "  def silence(config: AudioConfig, length_seconds: float | int) -> 'Audio':\n",
        "    frame = b'\\0' * config.frame_size\n",
        "    num_frames = int(length_seconds * config.sample_rate)\n",
        "    if num_frames < 0:\n",
        "      num_frames = 0\n",
        "    return Audio(config=config, data=frame * num_frames)\n",
        "\n",
        "  def as_numpy(self):\n",
        "    return np.frombuffer(self.data, dtype=self.config.numpy_dtype)\n",
        "\n",
        "  def as_wav_bytes(self) -> bytes:\n",
        "    buf = io.BytesIO()\n",
        "    with wave.open(buf, 'w') as wav:\n",
        "      wav.setnchannels(self.config.channels)\n",
        "      wav.setframerate(self.config.sample_rate)\n",
        "      assert self.config.format == 'S16_LE'\n",
        "      wav.setsampwidth(2)  # 16bit\n",
        "      wav.writeframes(self.data)\n",
        "    return buf.getvalue()\n",
        "\n",
        "  def _ipython_display_(self):\n",
        "    \"\"\"Hook displaying audio as HTML tag.\"\"\"\n",
        "    from IPython.display import display, HTML\n",
        "\n",
        "    b64_wav = base64.b64encode(self.as_wav_bytes()).decode('utf-8')\n",
        "    display(HTML(f\"\"\"\n",
        "        <audio controls>\n",
        "          <source src=\"data:audio/wav;base64,{b64_wav}\">\n",
        "        </audio>\n",
        "    \"\"\".strip()))\n",
        "\n",
        "  async def astream_realtime(\n",
        "      self, expected_delta_sec: float = 0.1\n",
        "  ) -> AsyncIterator[bytes]:\n",
        "    \"\"\"Yields audio data in chunks as if it was played realtime.\"\"\"\n",
        "    current_pos = 0\n",
        "    mono_start_ns = time.monotonic_ns()\n",
        "    while current_pos < len(self.data):\n",
        "      # print('sleep')\n",
        "      await asyncio.sleep(expected_delta_sec)\n",
        "      delta_ns = time.monotonic_ns() - mono_start_ns\n",
        "      expected_pos_frames = int(delta_ns * self.config.sample_rate / 1e9)\n",
        "      next_pos = expected_pos_frames * self.config.frame_size\n",
        "      # print (f'{next_pos = }, {current_pos =}, {len(self.data) = }')\n",
        "      if next_pos > current_pos:\n",
        "        yield self.data[current_pos:next_pos]\n",
        "        current_pos = next_pos\n",
        "\n",
        "  def __add__(self, other: 'Audio') -> 'Audio':\n",
        "    assert self.config == other.config\n",
        "    return Audio(config=self.config, data=self.data + other.data)\n",
        "\n",
        "\n",
        "class FailedToStartError(Exception):\n",
        "  \"\"\"Raised when audio session fails to start.\"\"\"\n",
        "\n",
        "\n",
        "class AudioSession:\n",
        "  \"\"\"Connection to audio recording/playback on client side.\"\"\"\n",
        "\n",
        "  def __init__(self, config: AudioConfig, connection: Connection):\n",
        "    self._config = config\n",
        "    self._connection = connection\n",
        "    self._done = False\n",
        "    self._read_queue: asyncio.Queue[bytes] = asyncio.Queue()\n",
        "    self._started = asyncio.Future()\n",
        "\n",
        "  @property\n",
        "  def config(self) -> AudioConfig:\n",
        "    return self._config\n",
        "\n",
        "  async def await_start(self):\n",
        "    await self._started\n",
        "\n",
        "  async def _read_loop(self):\n",
        "    # print ('read_loop')\n",
        "    while True:\n",
        "      # print ('await read')\n",
        "      data = await self._connection.read()\n",
        "      # print(\"data\", data)\n",
        "      if 'audio_in' in data:\n",
        "        # print(\"audio_in\", data['audio_in'])\n",
        "        raw_data = base64.b64decode(data['audio_in'].encode('utf-8'))\n",
        "        # print(\"audio_in\", raw_data)\n",
        "        self._read_queue.put_nowait(raw_data)\n",
        "      if 'started' in data:\n",
        "        self._started.set_result(None)\n",
        "      if 'failed_to_start' in data:\n",
        "        self._started.set_exception(\n",
        "            FailedToStartError(\n",
        "                f'Failed to start audio: {data[\"failed_to_start\"]}'\n",
        "            )\n",
        "        )\n",
        "\n",
        "  async def enqueue(self, audio_data: bytes):\n",
        "    b64_data = base64.b64encode(audio_data).decode('utf-8')\n",
        "    await self._connection.write({'audio_out': b64_data})\n",
        "\n",
        "  async def clear_queue(self):\n",
        "    await self._connection.write({'flush': True})\n",
        "\n",
        "  async def read(self) -> bytes:\n",
        "    return await self._read_queue.get()\n",
        "\n",
        "\n",
        "STANDARD_AUDIO_CONFIG = AudioConfig(sample_rate=16000, channels=1)\n",
        "\n",
        "\n",
        "# JavaScript code running in AudioWorklet, executing realtime audio processing.\n",
        "_audio_processor_worklet_js = \"\"\"\n",
        "class PortProcessor extends AudioWorkletProcessor {\n",
        "  constructor() {\n",
        "    super();\n",
        "    this._queue = [];\n",
        "    this.port.onmessage = (event) => {\n",
        "      //console.log(event.data);\n",
        "      if ('enqueue' in event.data) {\n",
        "        this.enqueueAudio(event.data.enqueue);\n",
        "      }\n",
        "      if ('clear' in event.data) {\n",
        "        this.clearAudio();\n",
        "      }\n",
        "    };\n",
        "    this._out = [];\n",
        "    this._out_len = 0;\n",
        "    console.log(\"PortProcessor ctor\", this);\n",
        "\n",
        "    this.port.postMessage({\n",
        "      debug: \"Hello from the processor!\",\n",
        "    });\n",
        "  }\n",
        "\n",
        "  encodeAudio(input) {\n",
        "    const channel = input[0];\n",
        "    const data = new ArrayBuffer(2 * channel.length);\n",
        "    const view = new DataView(data);\n",
        "    for (let i=0; i<channel.length; i++) {\n",
        "      view.setInt16(2*i, channel[i] * 32767, true);\n",
        "    }\n",
        "    return data;\n",
        "  }\n",
        "\n",
        "  enqueueAudio(input) { // bytearray\n",
        "    let view = new DataView(input);\n",
        "    let floats = [];\n",
        "    for (let i=0; i<input.byteLength; i+=2) {\n",
        "      floats.push(view.getInt16(i, true) / 32768.0);\n",
        "    }\n",
        "    this._queue.push(Float32Array.from(floats));\n",
        "  }\n",
        "\n",
        "  dequeueIntoBuffer(output) { // Float32Array\n",
        "    //console.log('deq', output)\n",
        "    let idx = 0;\n",
        "    while (idx < output.length) {\n",
        "      if (this._queue.length === 0) {\n",
        "        return;\n",
        "      }\n",
        "      let input = this._queue[0];\n",
        "      if (input.length == 0) {\n",
        "        this._queue.shift();\n",
        "        continue;\n",
        "      }\n",
        "      let n = Math.min(input.length, output.length - idx);\n",
        "      output.set(input.subarray(0, n), idx);\n",
        "      this._queue[0] = input.subarray(n);\n",
        "      idx += n;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  clearAudio() {\n",
        "    this._queue = [];\n",
        "  }\n",
        "\n",
        "  process(inputs, outputs, parameters) {\n",
        "    // forward input audio\n",
        "    let data = this.encodeAudio(inputs[0]);\n",
        "    this._out.push(data);\n",
        "    this._out_len += data.byteLength;\n",
        "    // only send in 50ms batches, ipykernel will die when it gets too frequent\n",
        "    if (this._out_len > (2*sampleRate / 20)) {\n",
        "      let concat = new Uint8Array(this._out_len);\n",
        "      let idx = 0;\n",
        "      for (let a of this._out) {\n",
        "        concat.set(new Uint8Array(a), idx);\n",
        "        idx += a.byteLength;\n",
        "      }\n",
        "      this._out = [];\n",
        "      this._out_len = 0;\n",
        "      this.port.postMessage({\n",
        "        'audio_in': concat.buffer,\n",
        "      });\n",
        "    }\n",
        "\n",
        "    // forward output\n",
        "    this.dequeueIntoBuffer(outputs[0][0]);\n",
        "    // copy to other channels\n",
        "    for (let i=1; i<outputs[0].length; i++) {\n",
        "      const src = outputs[0][0];\n",
        "      const dst = outputs[0][i];\n",
        "      dst.set(src.subarray(0, dst.length));\n",
        "    }\n",
        "    return true;\n",
        "  }\n",
        "}\n",
        "\n",
        "registerProcessor('port-processor', PortProcessor);\n",
        "\"\"\"\n",
        "\n",
        "# JavaScript code running in Colab UI IFrame.\n",
        "_audio_session_js = \"\"\"\n",
        "let audioCtx = new AudioContext({sampleRate: sample_rate});\n",
        "await audioCtx.audioWorklet.addModule(URL.createObjectURL(\n",
        "  new Blob([audio_worklet_js], {type: 'text/javascript'})\n",
        "));\n",
        "let userMedia;\n",
        "try {\n",
        "  userMedia = await navigator.mediaDevices.getUserMedia({\n",
        "    audio: {sampleRate: sample_rate, echoCancellation: true, channelCount: 1},\n",
        "  });\n",
        "} catch (e) {\n",
        "  connection.write({failed_to_start: e});\n",
        "  throw e;\n",
        "}\n",
        "console.log(\"colab_audio: userMedia=\", userMedia);\n",
        "connection.write({started: true})\n",
        "//await userMedia.getAudioTracks()[0].applyConstraints({channelCount: 1});\n",
        "\n",
        "try {\n",
        "  let source = audioCtx.createMediaStreamSource(userMedia);\n",
        "  let processor = new AudioWorkletNode(audioCtx, 'port-processor');\n",
        "  processor.port.onmessage = (event) => {\n",
        "    if ('audio_in' in event.data) {\n",
        "      // base64 encode ugly way\n",
        "      let encoded = btoa(String.fromCharCode(\n",
        "          ...Array.from(new Uint8Array(event.data.audio_in))));\n",
        "      //console.log(\"base64 input\", encoded);\n",
        "      connection.write({audio_in: encoded});\n",
        "    } else {\n",
        "      console.log(\"from processor (unhandled)\", event);\n",
        "    }\n",
        "  };\n",
        "  source.connect(processor);\n",
        "  processor.connect(audioCtx.destination);\n",
        "  //await new Promise((acc) => setTimeout(acc, 1000));\n",
        "  while(!connection.signal.aborted) {\n",
        "    let request = await connection.read();\n",
        "    //console.log(request);\n",
        "    if ('audio_out' in request) {\n",
        "      let decoded = Uint8Array.from(\n",
        "          atob(request.audio_out), c => c.charCodeAt(0)).buffer;\n",
        "      //console.log('Enqueue', decoded);\n",
        "      processor.port.postMessage({'enqueue': decoded});\n",
        "    } else if('flush' in request) {\n",
        "      processor.port.postMessage({'clear': ''});\n",
        "    }\n",
        "  }\n",
        "} finally {\n",
        "  userMedia.getTracks().forEach(t => t.stop());\n",
        "  audioCtx.close();\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "@contextlib.asynccontextmanager\n",
        "async def RunningLiveAudio(\n",
        "    config: AudioConfig = STANDARD_AUDIO_CONFIG, pump_interval=0.1\n",
        "):\n",
        "  \"\"\"Runs audio connection to Colab UI and returns `AudioConnection` connected to it.\"\"\"\n",
        "  assert config.channels == 1\n",
        "  assert config.format == 'S16_LE'\n",
        "  required_js = f\"\"\"\n",
        "    const audio_worklet_js = {json.dumps(_audio_processor_worklet_js)};\n",
        "    const sample_rate = {json.dumps(config.sample_rate)};\n",
        "    {_audio_session_js}\n",
        "  \"\"\"\n",
        "  try:\n",
        "    async with contextlib.AsyncExitStack() as stack:\n",
        "      tg = await stack.enter_async_context(asyncio.TaskGroup())\n",
        "      connection = await stack.enter_async_context(\n",
        "          RunningLiveJs(required_js, pump_interval)\n",
        "      )\n",
        "      session = AudioSession(config, connection)\n",
        "      read_task = tg.create_task(session._read_loop())  # copy data to queue\n",
        "      tg.create_task(session.await_start())  # fail session if it fails to start\n",
        "      yield session\n",
        "      read_task.cancel()\n",
        "  except asyncio.ExceptionGroup as e:\n",
        "    if len(e.exceptions) == 1:\n",
        "      raise e.exceptions[0]\n",
        "    else:\n",
        "      raise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLLTAfUjpBJ4"
      },
      "source": [
        "## Run the client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2leQzHwTqIOM",
        "outputId": "70fb9b9a-4c89-4d56-96ff-c935b279893c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'GOOGLE_API_KEY' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-26cd69acac0d>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mHOST\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'generativelanguage.googleapis.com'\u001b[0m \u001b[0;31m# @param {type:'string'}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mAPI_KEY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGOOGLE_API_KEY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mMODEL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'models/gemini-2.0-flash-exp'\u001b[0m \u001b[0;31m# @param {type:'string'}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mINITIAL_REQUEST_TEXT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"what's up?\"\u001b[0m \u001b[0;31m# @param {type:'string'}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'GOOGLE_API_KEY' is not defined"
          ]
        }
      ],
      "source": [
        "# @title Client implementation {display-mode: 'form'}\n",
        "# @markdown This cell runs client connection to BidiGenerate with realtime audio I/O\n",
        "from websockets.asyncio.client import connect\n",
        "import asyncio\n",
        "import contextlib\n",
        "import base64\n",
        "import json\n",
        "\n",
        "\n",
        "HOST = 'generativelanguage.googleapis.com' # @param {type:'string'}\n",
        "API_KEY = GOOGLE_API_KEY\n",
        "MODEL = 'models/gemini-2.0-flash-exp' # @param {type:'string'}\n",
        "INITIAL_REQUEST_TEXT = \"what's up?\" # @param {type:'string'}\n",
        "\n",
        "\n",
        "def encode_audio_input(data: bytes, config: AudioConfig) -> dict:\n",
        "  \"\"\"Build JSPB message with user input audio bytes.\"\"\"\n",
        "  return {\n",
        "      'realtimeInput': {\n",
        "          'mediaChunks': [{\n",
        "              'mimeType': f'audio/pcm;rate={config.sample_rate}',\n",
        "              'data': base64.b64encode(data).decode('UTF-8'),\n",
        "          }],\n",
        "      },\n",
        "  }\n",
        "\n",
        "\n",
        "def encode_text_input(text: str) -> dict:\n",
        "  \"\"\"Builds JSPB message with user input text.\"\"\"\n",
        "  return {\n",
        "      'clientContent': {\n",
        "          'turns': [{\n",
        "              'role': 'USER',\n",
        "              'parts': [{'text': text}],\n",
        "          }],\n",
        "          'turnComplete': True,\n",
        "      },\n",
        "  }\n",
        "\n",
        "\n",
        "def decode_audio_output(input: dict) -> bytes:\n",
        "  \"\"\"Returns byte string with model output audio.\"\"\"\n",
        "  result = []\n",
        "  content_input = input.get('serverContent', {})\n",
        "  content = content_input.get('modelTurn', {})\n",
        "  for part in content.get('parts', []):\n",
        "    data = part.get('inlineData', {}).get('data', '')\n",
        "    if data:\n",
        "      result.append(base64.b64decode(data))\n",
        "  return b''.join(result)\n",
        "\n",
        "\n",
        "async def main():\n",
        "  async with contextlib.AsyncExitStack() as es:\n",
        "    tg = await es.enter_async_context(asyncio.TaskGroup())\n",
        "    audio = await es.enter_async_context(RunningLiveAudio(AudioConfig(sample_rate=24000)))\n",
        "    conn = await es.enter_async_context(connect(f'wss://{HOST}/ws/google.ai.generativelanguage.v1alpha.GenerativeService.BidiGenerateContent?key={API_KEY}'))\n",
        "    print('<connected>')\n",
        "\n",
        "    initial_request = {\n",
        "        'setup': {\n",
        "            'model': MODEL,\n",
        "        },\n",
        "    }\n",
        "    await conn.send(json.dumps(initial_request))\n",
        "\n",
        "    if text := INITIAL_REQUEST_TEXT:\n",
        "      await conn.send(json.dumps(encode_text_input(text)))\n",
        "\n",
        "    async def send_audio():\n",
        "      while True:\n",
        "        data = await audio.read()\n",
        "        await conn.send(json.dumps(encode_audio_input(data, audio.config)))\n",
        "\n",
        "    tg.create_task(send_audio())\n",
        "    enqueued_audio = []\n",
        "    async for msg in conn:\n",
        "      msg = json.loads(msg)\n",
        "      if to_play := decode_audio_output(msg):\n",
        "        enqueued_audio.append(to_play)\n",
        "        await audio.enqueue(to_play)  # enqueue TTS\n",
        "      elif 'interrupted' in msg.get('serverContent', {}):\n",
        "        print('<interrupted by the user>')\n",
        "        await audio.clear_queue()  # stop TTS\n",
        "      elif 'turnComplete' in msg.get('serverContent', {}):\n",
        "        if enqueued_audio:  # display it for later playback\n",
        "          display.display(Audio(config=audio.config, data=b''.join(enqueued_audio)))\n",
        "        enqueued_audio = []\n",
        "        print('<end of turn>')\n",
        "      else:\n",
        "        if msg != {'serverContent': {}}:\n",
        "          print(f'unhandled message: {msg}')\n",
        "\n",
        "try:\n",
        "  await main()\n",
        "except asyncio.ExceptionGroup as e:\n",
        "  raise e.exceptions[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzmXBx1cBowf"
      },
      "source": [
        "**Important**: On first try it will typically throw an error and ask for permission to record audio, if that happens allow audio, and **run it again**."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "live_api_streaming_in_colab.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}